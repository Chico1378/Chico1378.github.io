<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.1.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/l4sq39yn.png.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/l4sq39yn.png.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="Ⅰ 数据处理阶段1. 数据来源监督微调的主要目的是学习是范式而不是知识，因此只通过监督微调学到的知识是有限的。对于构建航海大模型的任务来说，基础的模型底座Llama-Chat-7B只具备通用知识，并不具备领域知识，因此微调是必须的。我们收集以下三种数据集进行实验：  第一次微调数据集：从网站、文献中获得的航海知识纯文本或问答数据，用于第一次微调。初步采用英文数据（ArXiv，Book，Wik">
<meta property="og:type" content="article">
<meta property="og:title" content="KG增强的航海大模型实验">
<meta property="og:url" content="http://example.com/2024/04/09/Idea/index.html">
<meta property="og:site_name" content="Chico的私人空间">
<meta property="og:description" content="Ⅰ 数据处理阶段1. 数据来源监督微调的主要目的是学习是范式而不是知识，因此只通过监督微调学到的知识是有限的。对于构建航海大模型的任务来说，基础的模型底座Llama-Chat-7B只具备通用知识，并不具备领域知识，因此微调是必须的。我们收集以下三种数据集进行实验：  第一次微调数据集：从网站、文献中获得的航海知识纯文本或问答数据，用于第一次微调。初步采用英文数据（ArXiv，Book，Wik">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2024-04-09T04:31:59.993Z">
<meta property="article:modified_time" content="2024-04-09T06:57:47.982Z">
<meta property="article:author" content="Chico">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/2024/04/09/Idea/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>KG增强的航海大模型实验 | Chico的私人空间</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Chico的私人空间</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/04/09/Idea/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Chico">
      <meta itemprop="description" content="万事胜意">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chico的私人空间">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          KG增强的航海大模型实验
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2024-04-09 12:31:59 / 修改时间：14:57:47" itemprop="dateCreated datePublished" datetime="2024-04-09T12:31:59+08:00">2024-04-09</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <div style="text-align: justify;">


<h1 id="Ⅰ-数据处理阶段"><a href="#Ⅰ-数据处理阶段" class="headerlink" title="Ⅰ 数据处理阶段"></a>Ⅰ 数据处理阶段</h1><h3 id="1-数据来源"><a href="#1-数据来源" class="headerlink" title="1. 数据来源"></a>1. 数据来源</h3><p>监督微调的主要目的是学习是范式而不是知识，因此只通过监督微调学到的知识是有限的。对于构建航海大模型的任务来说，基础的模型底座Llama-Chat-7B只具备通用知识，并不具备领域知识，因此微调是必须的。我们收集以下三种数据集进行实验：</p>
<ul>
<li><p><strong>第一次微调数据集</strong>：从网站、文献中获得的航海知识纯文本或问答数据，用于第一次微调。初步采用英文数据（ArXiv，Book，Wikipedia）。</p>
</li>
<li><p><strong>第二次微调数据集</strong>：通过现有的船舶信息数据、即将有的锚地泊位、航线数据进行构造。</p>
</li>
<li><p><strong>外挂知识库</strong>：动态数据适合通过外挂知识库的形式被利用，因此船舶航行的AIS轨迹数据将经过处理后作为外挂知识库，执行下游任务，并在下游任务上进行模型效果的评估。</p>
</li>
</ul>
<p>第一次微调数据集的获取需要从互联网资源中去粗取精，精炼出高质量的预料库。因此对数据源的选取提出以下要求：</p>
<p>  （1）需要高质量的数据集。高质量数据集能够提高模型精度与可解释性，并且减少收敛到最优解的时间；信源需权威可靠、内容价值观对齐、具备专业的领域知识；数据集需要相关性、准确性、完备性、连贯性、安全性、专业性和时效性。</p>
<p>  （2）需要大规模的数据集。独立增加训练数据量、模型参数规模或者延长模型训练时间，模型的效果会越来越好。</p>
<p>  （3）需要多样性的数据集。数据丰富性能够提升模型的泛化能力，过于单一的数据容易让模型过于拟合训练数据。</p>
<h3 id="2-数据处理（具体实施方法待补充）"><a href="#2-数据处理（具体实施方法待补充）" class="headerlink" title="2. 数据处理（具体实施方法待补充）"></a>2. 数据处理（具体实施方法待补充）</h3><p>以下数据处理主要针对从网络上抓取的第一次微调数据:</p>
<h4 id="2-1-去重"><a href="#2-1-去重" class="headerlink" title="2.1 去重"></a>2.1 去重</h4><p>[文章去重算法]</p>
<h4 id="2-2-去毒：站点过滤、敏感与隐私过滤、语言或者噪声过滤"><a href="#2-2-去毒：站点过滤、敏感与隐私过滤、语言或者噪声过滤" class="headerlink" title="2.2 去毒：站点过滤、敏感与隐私过滤、语言或者噪声过滤"></a>2.2 去毒：站点过滤、敏感与隐私过滤、语言或者噪声过滤</h4><p>![站点过滤与噪声信息清洗] (Pic&#x2F;cb4f35a297e9457d60b8d192a55875e3~noop.png)</p>
<h4 id="2-3-网页主题建模"><a href="#2-3-网页主题建模" class="headerlink" title="2.3 网页主题建模"></a>2.3 网页主题建模</h4><p>![网页主题建模] (Pic&#x2F;8c03c759c18bf4cf09e4531c4e1878c2~noop.png)</p>
<h4 id="2-4-数据质量评分"><a href="#2-4-数据质量评分" class="headerlink" title="2.4 数据质量评分"></a>2.4 数据质量评分</h4><p>![数据质量控制] (Pic&#x2F;a8a55b4fa07445f3c205f54ef91673dd~noop.png)</p>
<h1 id="Ⅱ-用KG增强大语言模型问答效果"><a href="#Ⅱ-用KG增强大语言模型问答效果" class="headerlink" title="Ⅱ 用KG增强大语言模型问答效果"></a>Ⅱ 用KG增强大语言模型问答效果</h1><p>知识图谱（Knowledge Graph）是一种用于表示知识的结构化图形模型，它以图形的形式组织和呈现各种实体之间的关系和属性。其核心组成部分包括实体、属性和关系。通过将这些元素组织成图形结构，知识图谱可以捕捉丰富的语义信息，使得计算机系统能够更好地理解和推理数据。</p>
<p>大语言模型将知识隐式地存储于参数中，生成和问答能力强，但模型缺乏可解释性；知识图谱虽可以结构化地储存知识，但痛点在于图谱的构建和隐式关系的推理，并且缺乏动态规划的能力。两者之间的互补性掀起了研究KG+LLM应用的热潮。大模型可用于知识图谱的构建和补全，增强知识图谱问答和生成文本的能力；知识图谱可以强化大模型的推理能力、可解释性，也可作为提示工程引导大模型完成能力。本实验将考虑知识图谱单向增强大语言模型推理能力的情况，使用航海知识图谱对大语言模型进行微调，建立边海防领域的垂直大模型。</p>
<p>以下列出实验中用KG增强大模型问答的几个阶段：</p>
<h3 id="（1）微调数据生成"><a href="#（1）微调数据生成" class="headerlink" title="（1）微调数据生成"></a>（1）微调数据生成</h3><ol>
<li><p>利用大模型于数据清洗，构造清洗规则，其作为领域经验知识对特定语料进行错误检测或过滤。</p>
</li>
<li><p>第一次微调的数据大部分将会是文本形式；若爬取到部分数据是按照类似于三元组的形式排布，则可利用知识图谱直接显式的进行模板化拼接，引入第一次微调语料，比如使用行业三元组拼接成S+P+O、S的P是O、S的P等于O这样的<strong>描述性文本</strong>。</p>
</li>
<li><p><strong>基于知识图谱的微调数据生成</strong></p>
<p><a target="_blank" rel="noopener" href="https://qiankunli.github.io/2023/10/29/llm_finetune.html">《LLM微调理论及实践》</a>中提到，基于人工的领域微调数据生成较为困难，一般是基于已有数据+ChatGPT4的方式进行领域微调数据的生成。基于三种已有数据集，有三种方式生成微调数据：</p>
<p>（1）一些种子数据——<a href="(https://blog.csdn.net/qq_27590277/article/details/129761271)">Self Instruct</a>。如果已经一些种子微调数据(大约100条)，可以通过Self-Instruct+GPT4进行扩充，生成更多相对符合要求的微调数据。一条微调数据包括三个部分：指令，输入和输出。<a href="(https://finisky.github.io/lawyer-llama-summary/)">Lawyer LLaMA</a>这样的法律领域的行业模型，也是通过这样的方式结合知识图谱生成大量的监督微调数据。为了保证多样性，只有当一条新指令与任何现有指令的ROUGE-L重叠小于0.7时才会被保留。为了数据集的多样性，还可以用GPT-4或者其他大模型做改写，让指令复杂化，在指令的长度上，可以做一定的控制。</p>
<p>（2）文档数据——Self QA。如果连基础的种子指令数据都没有，那就不适于Self-Instruct的方法了。这时候可以尝试Self—QA的方法，直接从文档中生成指令数据。</p>
<p>（3）<strong>知识图谱——Self KG</strong>。如果一个领域已经有了高质量的知识图谱，也可以直接基于知识图谱生成指令数据。参考<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2304.06975.pdf">HuaTuo</a>。HuaTuo 大模型从知识图谱中提取了实例后，用OpenAI对每个实例进行知识拓展，最后收集了8000条指令微调数据。</p>
</li>
</ol>
<h2 id="（2）检索增强阶段"><a href="#（2）检索增强阶段" class="headerlink" title="（2）检索增强阶段"></a>（2）检索增强阶段</h2><p>目前，在垂直大模型的构建中，经常使用外挂知识库进行检索增强，并在此基础上进行下游评测的任务。<a target="_blank" rel="noopener" href="https://blog.csdn.net/sinat_19559525/article/details/136149360">《借助知识图谱和Llama-Index实现基于大模型的RAG》</a>中将外挂知识库分为向量数据库和知识图谱。向量数据库适合基于相似性的检索操作，知识图谱旨在捕捉和分析复杂的关系。</p>
<p>基于向量数据库的检索增强的主要流程为：加载文件-&gt;读取文本-&gt;文本分割-&gt;文本向量化-&gt;问句向量化-&gt;在文本向量中匹配出与问句向量最相似的top k个-&gt;匹配出的文本作为上下文和问题一起添加到prompt中-&gt;提交给大语言模型生成回答。其核心在于如何构造更好训练数据以优化向量化方案和嵌入，如何通过向量检索得到相关文本后，更好地拼接到Prompt中。</p>
<p>若以知识图谱的方式进行检索增强，则其基本思想在于用链接的方式召回子图，将相关的实体和关系拼接到Prompt中来增强结果的可用性，从知识图谱中查询背景知识放入上下文。首先，需要对用户提出的问题进行深入理解，包括问题的类型（事实型、解释型、推荐型等）、关键词和实体。这一步骤通常涉及自然语言处理技术，如实体识别、意图识别等。第二步，将问题中的关键词和实体映射到知识图谱中的相应实体和关系上，需要使用实体链接技术来识别和匹配知识图谱中的对应项。第三步，根据映射的实体和关系，设计查询语句或使用图查询语言（如SPARQL）来从知识图谱中检索相关信息。查询的目标是获取与问题相关的背景知识，这些知识可以帮助构建一个更加丰富和准确的上下文。第四步，使用从知识图谱中检索到的信息来组装Prompt，可能包括实体的定义、相关事件、人物之间的关系、地理位置、时间线等，Prompt应该围绕问题构建，提供足够的背景信息，以便问答系统能够生成一个全面的回答。最后，将Prompt集成到问答系统中，这可能涉及到将Prompt输入到的大语言模型中，或使用Prompt引导一个特定的搜索查询，在此阶段，问答系统将利用Prompt中的背景知识来生成或提炼出一个精确、详细的回答。</p>
<h2 id="（3）结果封装阶段"><a href="#（3）结果封装阶段" class="headerlink" title="（3）结果封装阶段"></a>（3）结果封装阶段</h2><p>在问答系统的结果封装阶段，知识图谱作为一种结构化的知识表示和存储方式，对于提升系统的知识准确性和可信度起着至关重要的作用。通过利用知识图谱，可以有效地进行知识修正和知识溯源，具体方法如下：</p>
<ol>
<li>知识修正</li>
</ol>
<ul>
<li>错误检测与纠正：利用自然语言处理技术，如语义分析和实体识别，对问答系统中的输出结果进行分析，以发现潜在的错误或不准确之处。结合知识图谱中的结构化数据，对检测到的问题进行验证和纠正。例如，如果系统输出了一个错误的实体关系，可以通过知识图谱中的逻辑约束和数据一致性规则来识别并修正这一错误。</li>
<li>信息的完整性与补充：通过比对知识图谱中的信息和问答系统的输出结果，识别出可能缺失的知识信息。利用外部数据源或专家知识，对知识图谱中的缺失信息进行补充和更新，确保问答系统的结果更加全面和准确。</li>
</ul>
<ol start="2">
<li>知识溯源</li>
</ol>
<ul>
<li>信息来源的记录与追踪：在知识图谱中为每个实体和关系记录详细的来源信息，包括原始数据源、数据抽取的时间和方法等。当问答系统生成结果时，同时提供这些结果对应的知识来源信息，使用户能够了解知识背后的依据。</li>
<li>推理路径的追踪与解释：记录从原始数据到最终结论的整个推理过程，包括使用的算法、逻辑规则和数据分析方法。在问答系统的结果封装中，提供这些推理路径的可视化解释，帮助用户理解系统是如何得出特定答案的。</li>
</ul>
<h1 id="Ⅲ-性能评估方法"><a href="#Ⅲ-性能评估方法" class="headerlink" title="Ⅲ 性能评估方法"></a>Ⅲ 性能评估方法</h1><p>模型性能的评估基本上有三种方式：</p>
<ol>
<li><p>基于人工业务评估，人工根据特定的业务场景找到需要评估的能力点（如摘要能力，生成能力等）通过列举相关测试样本，建立评估维度，完成多维度打分。</p>
</li>
<li><p>基于下游任务评测，利用下游评测榜单，任务数据集，进行性能评估。</p>
</li>
<li><p>利用ChatGPT 的专业能力，令其充当裁判，完成打分评估。Vicuna 就采取了这种评估方案。</p>
</li>
</ol>
<p>本实验的主要基于下游任务进行置信度评估、一致性评估和Chatgpt自动化评估。</p>
<h3 id="1-置信度评估（logit-based-method）"><a href="#1-置信度评估（logit-based-method）" class="headerlink" title="1. 置信度评估（logit-based method）"></a>1. 置信度评估（logit-based method）</h3><ul>
<li><strong>Token 级概率</strong>：对于每个 token，模型会输出一个概率分布，表示该 token 在所有可能的候选 token 中出现的概率。计算 token 级概率的方法通常是将模型输出的概率分布中对应于每个 token 的概率相乘，然后取自然对数（或者对数概率）以避免下溢或浮点数不稳定性。最终，可以将所有 token 的对数概率求和，得到整个答案的 token 级概率。</li>
<li><strong>熵</strong>：<br>熵是衡量一个概率分布的不确定性的指标，也可以用于评估模型回答的置信度。对于模型输出的概率分布，计算其熵可以使用以下公式:<br>$$H(X)&#x3D;-\sum_{i&#x3D;1}^{n}P(x_i)logP(x_i)$$<br>其中，$P(x_i)$是第 $i$ 个 token 的概率。熵越大，表示概率分布越均匀，模型的答案可能性也就越不确定；而熵越小，则表示概率分布更加集中，模型的答案可能性更为确定。通过计算 token 级概率或熵，可以量化模型对于给定问题答案的置信度。通常情况下，较高的 token 级概率或较低的熵值表示模型对于给定问题的答案具有更高的置信度。</li>
</ul>
<h3 id="2-一致性评估（consistency-based-method）"><a href="#2-一致性评估（consistency-based-method）" class="headerlink" title="2. 一致性评估（consistency-based method）"></a>2. 一致性评估（consistency-based method）</h3><p><a href="(https://blog.csdn.net/skying159/article/details/120702567)">BERTScore</a>是一种用于评估自然语言生成模型生成文本质量的指标，它通过计算模型生成的文本与参考文本之间的相似度来评估模型的性能,可以量化模型生成的文本与参考文本之间的相似度，从而更准确地评估回答的置信度。以下是一般的评估步骤：</p>
<ol>
<li>准备一组参考文本（即人类生成或标记的文本）和模型生成的文本（即系统回答的文本）。</li>
<li>计算BERTScore：使用BERTScore库计算模型生成的文本与参考文本之间的相似度得分。BERTScore通过将文本编码为BERT模型的隐藏表示，并计算隐藏表示之间的余弦相似度来度量文本之间的相似度。</li>
<li>评估一致性：通过比较模型生成的文本与参考文本之间的BERTScore得分，可以评估模型生成的文本的一致性。如果模型生成的文本与多个参考文本之间的BERTScore得分接近，则说明回答具有较高的一致性。</li>
</ol>
<h3 id="3-自动化评估（verballize-based-method）"><a href="#3-自动化评估（verballize-based-method）" class="headerlink" title="3. 自动化评估（verballize-based method）"></a>3. 自动化评估（verballize-based method）</h3><p>给ChatGPT一个问题和答案对，设计Prompt要求其对答案进行打分，打分区间为0到1，要求其打分并给出依据。</p>
<h2 id="Ⅳ-实验阶段"><a href="#Ⅳ-实验阶段" class="headerlink" title="Ⅳ 实验阶段"></a>Ⅳ 实验阶段</h2><h3 id="1-模型底座"><a href="#1-模型底座" class="headerlink" title="1. 模型底座"></a>1. 模型底座</h3><p>Llama2在问答、生成、对话任务上均表现出出色的性能，其预训练模型包含7B、13B和70B三个版本。开发者在此基础上进行监督微调，获得了对话能力更强的chat模型，即Llama2-Chat。</p>
<p>为提升Llama2在中文语境下的对话能力，开发者在Llama2-Chat的基础上进行微调，得到Llama2-Chinese，其能够理解中文文本的语义、结构和上下文，并生成流畅自然的中文文本。而Atom是基于Llama2模型的中文预训练模型，从头开始使用大规模数据进行训练和优化，使Atom具备了强大的中文理解和生成能力。</p>
<p>垂直行业大模型的部署对大模型底座的对话能力有一定要求，因此本实验选择Llama2-Chat-7B，以Llama2-Chat-13B和ChatGPT4作为基准模型进行比较。</p>
<h3 id="2-微调"><a href="#2-微调" class="headerlink" title="2. 微调"></a>2. 微调</h3><p>大语言模型的微调过程是一种优化技术，它通过在特定任务的数据集上进一步训练预训练的语言模型，来适应特定的应用场景。在这个过程中，模型的权重会根据任务相关的数据进行调整，以便更好地理解和生成与该任务相关的文本。微调通常涉及选择一个较小的数据集，这个数据集包含了任务的样本，如文本分类、问答或文本生成等。通过这种方式，模型能够学习到与特定任务相关的语言模式和结构，从而在执行该任务时表现得更加精准和有效。微调不仅可以提高模型的性能，还可以使其在处理新任务时具有更好的泛化能力。</p>
<p>航海大模型第一次微调数据将使用大量爬取的航海文本知识数据，提高领域适应性，增强大模型的上下文理解能力。</p>
<p>第二次微调数据的生成将利用厦门港口的船舶信息、港口信息、航道信息知识图谱进行构建，增强地域性知识理解。当下掌握了2023年厦门港口的AIS数据和船舶信息数据，这些.dmp形式数据导出后通过oracle转存为.csv文件。若能获取港口、航道的信息数据，则可以用大模型复现梅强老师的工作，并在此基础之上衍生出基于KG+LLM的船舶分类、锚位推荐等下游任务。数据集内的每条数据都可表示为（实体，关系，属性）的形式；不同数据集之间的实体则可以表示为（头实体、关系、尾实体）的形式。</p>
<ol>
<li><p>Voyage数据存储了2021年到2024年通行船只的静态信息，包括：船名、ID、船长度、船宽度、出水深度、目的地、船舶类型。清理缺失数据后，根据基本信息建立（实体，关系，属性）三元组实例。</p>
</li>
<li><p>对每一个船舶实例，利用ChatGPT4生成指令微调QA对数据。Input为问题，Output为回答，并使用ChatGPT4对每一个船舶实例进行内容扩充，丰富数据集的多样性（部分大船的信息能够被检索到）。<code>需要考虑具体问题是什么</code></p>
</li>
</ol>
<table>
<thead>
<tr>
<th>1 三元组</th>
</tr>
</thead>
<tbody><tr>
<td>{“船舶_类”: [{“ID”: “SA 440174000”,”船名”: “FEG SUCCESS”,”船长”: “292”,”船宽”: “46”,”排水量”: “8”,”目的地”: “SGSIN PJSB”,”船舶类型”: “70”}</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>2 QA对</th>
</tr>
</thead>
<tbody><tr>
<td>{“text”:”###Human:FEG SUCCESS的尺寸为长292米，宽46米，排水量为8，通常它可能是哪种类型的船舶？\n###Assistant:\n该船舶可能属于船舶类型70。”}</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th>3 内容扩充</th>
</tr>
</thead>
<tbody><tr>
<td>{“text”:”###Human:FEG SUCCESS的尺寸为长292米，宽46米，排水量为8，通常它可能是哪种类型的船舶？\n###Assistant:\n该船舶可能属于船舶类型70。该船是由川崎造船设计开发，是能够进入法国敦刻尔克港口的船舶中运力最大的船舶之一，并且完全符合加强安全型散货船船体强度规则（国际船级社共同结构规范）。此外，为了提高节油效率，该船采用了带对转鳍的川崎半管道系统和一个带鳍的带球鼻舵。”}</td>
</tr>
</tbody></table>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">评估任务一：船舶类型预测。船舶类型和船舶长度、宽度、排水量、目的地等有潜在语义关系，因此可以设定问答数据集，培养大模型对于船舶类型预测问题的能力。预测结果将与KNN、决策树、随机森林、SVM、高斯朴素贝叶斯等机器学习分类方法进行比较，评估指标为精确率、召回率和F1分数。</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th align="center">方法</th>
<th align="center">精确率</th>
<th align="center">召回率</th>
<th align="center">F1分数</th>
</tr>
</thead>
<tbody><tr>
<td align="center">Llama-7B-Chat</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
</tr>
<tr>
<td align="center">KNN</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">决策树</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">随机森林</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">SVM</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">高斯朴素贝叶斯</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
</tbody></table>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">评估任务二：船舶基本信息查询。输入船舶名称或mmsi，对船舶基本信息进行提问。</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th align="center">模型</th>
<th align="center">置信度</th>
<th align="center">一致性</th>
<th align="center">ChatGPT4自动评估</th>
</tr>
</thead>
<tbody><tr>
<td align="center">Llama-7B-Chat</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
</tr>
<tr>
<td align="center">Llama-13B-Chat</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr>
<td align="center">ChatGPT4</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
</tbody></table>
<h3 id="3-检索增强生成"><a href="#3-检索增强生成" class="headerlink" title="3. 检索增强生成"></a>3. 检索增强生成</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">评估任务三：嫌疑船只检测。</span><br><span class="line"></span><br><span class="line">背景：发现一艘嫌疑船只A，通过输入A船的轨迹，检索出与A的轨迹相似的前20条船并排序，重点关注相似度高的几艘船，相似度高的船只可能也存在嫌疑行为。由于历史AIS数据中并不一定存在异常的轨迹，因此将任务转变为普通船只轨迹相似度查询。</span><br></pre></td></tr></table></figure>

<p>该任务基于相似度计算进行实现。以下提供两种计算方案并进行比较：</p>
<p><strong>方案一</strong>：用轨迹数据直接构建向量数据库。将轨迹数据向量化，保存为json文件，每一条船只有一条或几条特定轨迹。提示LLM从知识库中匹配出与船只A的轨迹最为相似的top k条数据加入Prompt，LLM根据新的Prompt回答船只A与这些轨迹的相似度。</p>
<p>Prompt：<br>根据嫌疑船只A的轨迹向量，搜索并列出知识库中最相似的前20条轨迹。对于每条返回的轨迹，请提供其船只ID和相似度评分，</p>
<p><strong>方案二</strong>：对AIS航迹进行处理，深入挖掘航迹知识，用<a target="_blank" rel="noopener" href="https://www.dqxxkx.cn/CN/10.12082/dqxxkx.2023.210631">Stop&#x2F;Move</a>模型从AIS数据中提取语义信息后，构建知识图谱，并用自然语言表述船只轨迹，最后通过RAG获取相似度高的表述。具体步骤如下：</p>
<p> [1]. 轨迹点序列的准备：首先，需要收集船舶的轨迹数据，这些数据通常包含船舶在一定时间间隔内的位置信息（如经度和纬度）。</p>
<p> [2]. 识别停留点（Stop）：通过分析轨迹点序列，可以识别出船舶在一段时间内位置基本保持不变的点。这些点被认为是船舶的停留点。例如，如果船舶在港口停留或者在某个海域进行作业，其轨迹点会在地图上形成一个密集区域，这些区域就可以被视为停留点。</p>
<p> [3]. 识别移动段（Move）：与停留点相对的是移动段，它们表示船舶在两个停留点之间或者从一个海域转移到另一个海域的连续移动。通过连接停留点之间的轨迹点，可以形成船舶的移动路径。</p>
<p> [4]. 计算和分析：在识别出停留点和移动段之后，可以对这些数据进行进一步的计算和分析，例如计算船舶的航速、航向，以及停留的时间长度等。</p>
<p> [5]. 与地理空间要素关联：将提取出的Stop&#x2F;Move信息与地理空间要素（如港口、海域边界等）进行关联，以挖掘更深层次的语义知识。例如，通过分析船舶进入和离开港口的行为，可以识别出船舶的装卸货活动。</p>
<p> [6]. 构建知识图谱：最后，将提取的语义信息整合到知识图谱中，形成船舶活动的实例层，这为后续的查询、分析和可视化提供了基础。</p>
<p> [7]. 自然语言描述航行轨迹。将船只轨迹知识图谱的移动、停泊行为串联，描述船舶在整个航程中的行为，保存为json文件作为检索知识库。</p>
<p>在检索增强知识库构建完成后，应用Langchain检索相似轨迹并设计Prompt计算出相似度。</p>
<h3 id="3-知识修正"><a href="#3-知识修正" class="headerlink" title="3. 知识修正"></a>3. 知识修正</h3><p>基于轨迹语义的船舶活动知识图谱可以为大语言模型问答系统提供精确、结构化的知识支持，从而对问答结果进行知识修正和增强。这种结合可以确保回答的准确性和相关性，尤其是在处理复杂和专业的海事问题时。</p>
<p>以下是一个例子，说明如何运用基于轨迹语义的船舶活动知识图谱对LLM问答系统进行知识修正：</p>
<p>用户通过问答系统向LLM提出问题，例如：“船只XYZ在2023年4月5日的航行轨迹是什么？”LLM根据其内置的知识库和学习数据尝试回答用户的问题，但由于LLM的知识可能不是实时更新的，其回答可能不完全准确或不包含最新的轨迹信息（Context-Memory Conflict）。为了提供更准确的回答，系统将问题转交给基于轨迹语义的船舶活动知识图谱进行知识修正。知识图谱通过访问最新的AIS数据和其他相关海事数据源，提取船只XYZ在指定日期的精确轨迹信息。大模型分析船只XYZ的轨迹数据，识别出关键的活动节点，如起始点、停留点、加速和减速区域等，并将这些信息转化为易于理解的自然语言描述。LLM结合原有的回答和知识图谱提供的详细信息，生成一个更加准确和详细的回答。最终，系统向用户提供了一个结合了实时数据和专业知识的修正答案，例如：“船只XYZ在2023年4月5日从A港口出发，经过B海域，在C点停留了2小时进行货物装卸，随后以每小时15节的速度向D港口航行，期间在E海域遇到了减速区域，最终在D港口于晚上8点停靠。”通过这种方式，基于轨迹语义的船舶活动知识图谱不仅增强了LLM的问答质量，还提供了更加丰富和精确的信息，使用户能够获得更满意的回答。这种结合也提高了问答系统在处理海事相关问题时的专业性和可靠性。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">评估任务四：应用航海知识图谱进行知识修正</span><br></pre></td></tr></table></figure>

<p>实验步骤如下：</p>
<p>[1]问题生成：设计一系列关于特定船只在特定日期的航行轨迹的问题，这些问题应该能够覆盖不同的查询场景。</p>
<p>[2]LLM初始回答：使用LLM对生成的问题进行初始回答，不借助外部知识图谱。记录每个问题的回答内容和生成时间。</p>
<p>[3]知识图谱辅助回答：对于每个问题，使用知识图谱提供的信息辅助LLM生成修正后的回答。确保修正后的回答包含关键活动节点和详细的航行信息。</p>
<p>[4]评估指标：定义评估指标，如准确度、完整性、相关性、及时性等。设计自动化脚本来计算这些指标，以便对LLM的初始回答和修正后的回答进行评估。</p>
<p>[5]结果比较与分析：对比LLM的初始回答和修正后的回答，分析知识修正的效果。使用统计方法来确定修正是否显著提高了回答质量。</p>
</div>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2024/04/09/hello-world/" rel="prev" title="Hello World">
      <i class="fa fa-chevron-left"></i> Hello World
    </a></div>
      <div class="post-nav-item"></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E2%85%A0-%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E9%98%B6%E6%AE%B5"><span class="nav-number">1.</span> <span class="nav-text">Ⅰ 数据处理阶段</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-%E6%95%B0%E6%8D%AE%E6%9D%A5%E6%BA%90"><span class="nav-number">1.0.1.</span> <span class="nav-text">1. 数据来源</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%EF%BC%88%E5%85%B7%E4%BD%93%E5%AE%9E%E6%96%BD%E6%96%B9%E6%B3%95%E5%BE%85%E8%A1%A5%E5%85%85%EF%BC%89"><span class="nav-number">1.0.2.</span> <span class="nav-text">2. 数据处理（具体实施方法待补充）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-1-%E5%8E%BB%E9%87%8D"><span class="nav-number">1.0.2.1.</span> <span class="nav-text">2.1 去重</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-%E5%8E%BB%E6%AF%92%EF%BC%9A%E7%AB%99%E7%82%B9%E8%BF%87%E6%BB%A4%E3%80%81%E6%95%8F%E6%84%9F%E4%B8%8E%E9%9A%90%E7%A7%81%E8%BF%87%E6%BB%A4%E3%80%81%E8%AF%AD%E8%A8%80%E6%88%96%E8%80%85%E5%99%AA%E5%A3%B0%E8%BF%87%E6%BB%A4"><span class="nav-number">1.0.2.2.</span> <span class="nav-text">2.2 去毒：站点过滤、敏感与隐私过滤、语言或者噪声过滤</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-3-%E7%BD%91%E9%A1%B5%E4%B8%BB%E9%A2%98%E5%BB%BA%E6%A8%A1"><span class="nav-number">1.0.2.3.</span> <span class="nav-text">2.3 网页主题建模</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-4-%E6%95%B0%E6%8D%AE%E8%B4%A8%E9%87%8F%E8%AF%84%E5%88%86"><span class="nav-number">1.0.2.4.</span> <span class="nav-text">2.4 数据质量评分</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E2%85%A1-%E7%94%A8KG%E5%A2%9E%E5%BC%BA%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E9%97%AE%E7%AD%94%E6%95%88%E6%9E%9C"><span class="nav-number">2.</span> <span class="nav-text">Ⅱ 用KG增强大语言模型问答效果</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%EF%BC%881%EF%BC%89%E5%BE%AE%E8%B0%83%E6%95%B0%E6%8D%AE%E7%94%9F%E6%88%90"><span class="nav-number">2.0.1.</span> <span class="nav-text">（1）微调数据生成</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%EF%BC%882%EF%BC%89%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E9%98%B6%E6%AE%B5"><span class="nav-number">2.1.</span> <span class="nav-text">（2）检索增强阶段</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%EF%BC%883%EF%BC%89%E7%BB%93%E6%9E%9C%E5%B0%81%E8%A3%85%E9%98%B6%E6%AE%B5"><span class="nav-number">2.2.</span> <span class="nav-text">（3）结果封装阶段</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E2%85%A2-%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E6%96%B9%E6%B3%95"><span class="nav-number">3.</span> <span class="nav-text">Ⅲ 性能评估方法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-%E7%BD%AE%E4%BF%A1%E5%BA%A6%E8%AF%84%E4%BC%B0%EF%BC%88logit-based-method%EF%BC%89"><span class="nav-number">3.0.1.</span> <span class="nav-text">1. 置信度评估（logit-based method）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-%E4%B8%80%E8%87%B4%E6%80%A7%E8%AF%84%E4%BC%B0%EF%BC%88consistency-based-method%EF%BC%89"><span class="nav-number">3.0.2.</span> <span class="nav-text">2. 一致性评估（consistency-based method）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-%E8%87%AA%E5%8A%A8%E5%8C%96%E8%AF%84%E4%BC%B0%EF%BC%88verballize-based-method%EF%BC%89"><span class="nav-number">3.0.3.</span> <span class="nav-text">3. 自动化评估（verballize-based method）</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E2%85%A3-%E5%AE%9E%E9%AA%8C%E9%98%B6%E6%AE%B5"><span class="nav-number">3.1.</span> <span class="nav-text">Ⅳ 实验阶段</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-%E6%A8%A1%E5%9E%8B%E5%BA%95%E5%BA%A7"><span class="nav-number">3.1.1.</span> <span class="nav-text">1. 模型底座</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-%E5%BE%AE%E8%B0%83"><span class="nav-number">3.1.2.</span> <span class="nav-text">2. 微调</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90"><span class="nav-number">3.1.3.</span> <span class="nav-text">3. 检索增强生成</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-%E7%9F%A5%E8%AF%86%E4%BF%AE%E6%AD%A3"><span class="nav-number">3.1.4.</span> <span class="nav-text">3. 知识修正</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Chico</p>
  <div class="site-description" itemprop="description">万事胜意</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">2</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Chico</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>


  <script defer src="/lib/three/three.min.js"></script>
    <script defer src="/lib/three/three-waves.min.js"></script>


  















  

  

</body>
</html>
